# üßπ Quy Tr√¨nh L√†m S·∫°ch D·ªØ Li·ªáu Chi Ti·∫øt

## T·ªïng Quan

Quy tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu ƒë∆∞·ª£c thi·∫øt k·∫ø th√†nh **8 b∆∞·ªõc tu·∫ßn t·ª±**, chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√¥ th√†nh d·ªØ li·ªáu s·∫°ch ph·ª•c v·ª• cho ph√¢n t√≠ch v√† x√¢y d·ª±ng m√¥ h√¨nh.

### K·∫øt Qu·∫£ T·ªïng Quan

| Ch·ªâ s·ªë | Gi√° tr·ªã |
|--------|---------|
| D·ªØ li·ªáu th√¥ (input) | 85,470 b·∫£n ghi |
| D·ªØ li·ªáu s·∫°ch (output) | 81,971 b·∫£n ghi |
| S·ªë b·∫£n ghi b·ªã lo·∫°i | 3,499 (4.1%) |
| T·ª∑ l·ªá gi·ªØ l·∫°i | 95.9% |
| S·ªë c·ªôt d·ªØ li·ªáu | 11 c·ªôt g·ªëc + 8 c·ªôt m·ªõi |

---

## üìã B∆Ø·ªöC 0: CHU·∫®N B·ªä D·ªÆ LI·ªÜU

### 0.1 Normalize Text Columns

**M·ª•c ti√™u:** Chu·∫©n h√≥a c√°c c·ªôt vƒÉn b·∫£n v·ªÅ d·∫°ng lowercase v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a.

**C√°c c·ªôt ƒë∆∞·ª£c x·ª≠ l√Ω:**
- `job_title`, `job_type`, `position_level`, `city`
- `experience`, `skills`, `job_fields`, `unit`

**Code th·ª±c hi·ªán:**
```python
text_cols = ['job_title', 'job_type', 'position_level', 'city', 
             'experience', 'skills', 'job_fields', 'unit']
for col in text_cols:
    df[col] = df[col].astype(str).str.lower().str.strip()
```

### 0.2 Handle 'nan' Strings

**M·ª•c ti√™u:** Chuy·ªÉn chu·ªói 'nan' (do ƒë·ªçc t·ª´ CSV) th√†nh gi√° tr·ªã NaN th·ª±c s·ª±.

```python
for col in ['skills', 'job_fields', 'unit', 'city', 'experience', 'position_level', 'job_type']:
    df[col] = df[col].replace('nan', np.nan)
```

---

## üìç B∆Ø·ªöC 1: CHU·∫®N H√ìA T√äN TH√ÄNH PH·ªê

### V·∫•n ƒë·ªÅ

D·ªØ li·ªáu th√¥ ch·ª©a **466 bi·∫øn th·ªÉ kh√°c nhau** c·ªßa t√™n th√†nh ph·ªë do:
- Vi·∫øt kh√¥ng d·∫•u / c√≥ d·∫•u
- Vi·∫øt t·∫Øt kh√°c nhau (HCM, TPHCM, TP.HCM)
- Ti·∫øng Anh / ti·∫øng Vi·ªát
- Sai ch√≠nh t·∫£

### Gi·∫£i ph√°p

X√¢y d·ª±ng **t·ª´ ƒëi·ªÉn √°nh x·∫° (mapping dictionary)** ƒë·ªÉ chu·∫©n h√≥a.

**V√≠ d·ª• mapping:**
```python
city_mapping = {
    # Major cities - various Vietnamese forms
    'h·ªì ch√≠ minh': 'Ho Chi Minh City',
    'ho chi minh': 'Ho Chi Minh City',
    'hcm': 'Ho Chi Minh City',
    'tp.hcm': 'Ho Chi Minh City',
    'tp hcm': 'Ho Chi Minh City',
    'tphcm': 'Ho Chi Minh City',
    's√†i g√≤n': 'Ho Chi Minh City',
    'saigon': 'Ho Chi Minh City',
    
    'h√† n·ªôi': 'Hanoi',
    'ha noi': 'Hanoi',
    'hn': 'Hanoi',
    
    'ƒë√† n·∫µng': 'Da Nang',
    'da nang': 'Da Nang',
    
    # ... 63 t·ªânh/th√†nh ph·ªë kh√°c
    
    'to√†n qu·ªëc': 'Nationwide',
    'toan quoc': 'Nationwide',
    'all': 'Nationwide',
}
```

**H√†m chu·∫©n h√≥a:**
```python
def standardize_city(city_val):
    if pd.isna(city_val):
        return np.nan
    city_lower = str(city_val).lower().strip()
    
    # Direct mapping
    if city_lower in city_mapping:
        return city_mapping[city_lower]
    
    # Partial match for compound names
    for key, value in city_mapping.items():
        if key in city_lower:
            return value
    
    # Title case fallback for unmapped cities
    return city_val.title()

df['city'] = df['city'].apply(standardize_city)
```

### K·∫øt qu·∫£
- **Tr∆∞·ªõc:** 466 unique values
- **Sau:** 415 unique values
- Gi·∫£m ~11% s·ªë l∆∞·ª£ng gi√° tr·ªã unique

---

## üí± B∆Ø·ªöC 2: CHU·∫®N H√ìA ƒê∆†N V·ªä TI·ªÄN T·ªÜ

### V·∫•n ƒë·ªÅ

M·ªôt s·ªë tin tuy·ªÉn d·ª•ng (ƒë·∫∑c bi·ªát c√¥ng ty n∆∞·ªõc ngo√†i) ghi l∆∞∆°ng b·∫±ng **USD** thay v√¨ VND.

### Gi·∫£i ph√°p

√Åp d·ª•ng t·ª∑ gi√° quy ƒë·ªïi c·ªë ƒë·ªãnh: **1 USD = 25,000 VND**

```python
USD_TO_VND_RATE = 25000

usd_mask = df['unit'].astype(str).str.lower().str.contains('usd', na=False)
usd_converted = int(usd_mask.sum())

if usd_converted > 0:
    # Convert to million VND
    df.loc[usd_mask, 'salary_min'] = df.loc[usd_mask, 'salary_min'] * USD_TO_VND_RATE / 1_000_000
    df.loc[usd_mask, 'salary_max'] = df.loc[usd_mask, 'salary_max'] * USD_TO_VND_RATE / 1_000_000
    df.loc[usd_mask, 'unit'] = 'vnd'
```

### K·∫øt qu·∫£
- **713 b·∫£n ghi** ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi t·ª´ USD sang VND
- ƒê·∫£m b·∫£o t√≠nh nh·∫•t qu√°n v·ªÅ ƒë∆°n v·ªã trong to√†n b·ªô dataset

---

## ‚úÖ B∆Ø·ªöC 3: KI·ªÇM TRA T√çNH H·ª¢P L·ªÜ C·ª¶A M·ª®C L∆Ø∆†NG

### V·∫•n ƒë·ªÅ

M·ªôt s·ªë b·∫£n ghi c√≥ l∆∞∆°ng t·ªëi thi·ªÉu **l·ªõn h∆°n** l∆∞∆°ng t·ªëi ƒëa - ƒë√¢y l√† l·ªói nh·∫≠p li·ªáu t·ª´ ph√≠a nh√† tuy·ªÉn d·ª•ng.

### Gi·∫£i ph√°p

Lo·∫°i b·ªè c√°c b·∫£n ghi kh√¥ng h·ª£p l·ªá:
```python
salary_invalid = df['salary_min'] > df['salary_max']
n_invalid = int(salary_invalid.sum())  # = 3,495
df = df[~salary_invalid].copy()
```

### X·ª≠ l√Ω gi√° tr·ªã l∆∞∆°ng = 0

L∆∞∆°ng b·∫±ng 0 th∆∞·ªùng l√† gi√° tr·ªã m·∫∑c ƒë·ªãnh khi kh√¥ng c√≥ th√¥ng tin ‚Üí chuy·ªÉn th√†nh NaN:
```python
salary_zero = (df['salary_min'] == 0) | (df['salary_max'] == 0)
n_zero = int(salary_zero.sum())  # = 2,202

df.loc[df['salary_min'] == 0, 'salary_min'] = np.nan
df.loc[df['salary_max'] == 0, 'salary_max'] = np.nan
```

### K·∫øt qu·∫£
- **3,495 b·∫£n ghi** b·ªã lo·∫°i do salary_min > salary_max
- **2,202 b·∫£n ghi** c√≥ gi√° tr·ªã 0 ƒë∆∞·ª£c chuy·ªÉn th√†nh NaN

---

## üè∑Ô∏è B∆Ø·ªöC 4: X·ª¨ L√ù MISSING SALARIES

### V·∫•n ƒë·ªÅ

Kho·∫£ng 80% tin tuy·ªÉn d·ª•ng kh√¥ng c√¥ng khai th√¥ng tin l∆∞∆°ng (ghi "th·ªèa thu·∫≠n" ho·∫∑c "c·∫°nh tranh").

### Gi·∫£i ph√°p

**Ph∆∞∆°ng √°n A: G·∫Øn c·ªù (Flag)**
```python
both_missing = df['salary_min'].isna() & df['salary_max'].isna()
df['has_salary'] = ~both_missing
```

**Ph∆∞∆°ng √°n B: Imputation (d√πng cho ph√¢n t√≠ch)**
S·ª≠ d·ª•ng **median theo ng√†nh ngh·ªÅ** ƒë·ªÉ ƒëi·ªÅn gi√° tr·ªã thi·∫øu:
```python
# Industry-based imputation
industry_salary_avg = df.groupby('job_fields')['salary_min'].transform('median')
df['salary_min_imputed'] = df['salary_min'].fillna(industry_salary_avg)

industry_salary_max_avg = df.groupby('job_fields')['salary_max'].transform('median')
df['salary_max_imputed'] = df['salary_max'].fillna(industry_salary_max_avg)
```

### K·∫øt qu·∫£
- T·∫°o c·ªôt `has_salary` ƒë·ªÉ ƒë√°nh d·∫•u b·∫£n ghi c√≥ th√¥ng tin l∆∞∆°ng
- T·∫°o c·ªôt `salary_min_imputed` v√† `salary_max_imputed` cho ph√¢n t√≠ch

---

## üîç B∆Ø·ªöC 5: PH√ÅT HI·ªÜN V√Ä G·∫ÆN C·ªú B·∫¢N GHI TR√ôNG L·∫∂P

### V·∫•n ƒë·ªÅ

Do thu th·∫≠p t·ª´ nhi·ªÅu ngu·ªìn v√† nhi·ªÅu th·ªùi ƒëi·ªÉm, c√≥ th·ªÉ c√≥ c√°c tin tuy·ªÉn d·ª•ng tr√πng l·∫∑p.

### Gi·∫£i ph√°p

**L∆∞u √Ω:** Do d·ªØ li·ªáu **kh√¥ng c√≥ c·ªôt `company_name`**, kh√¥ng th·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c tr√πng l·∫∑p ‚Üí ch·ªâ **g·∫Øn c·ªù** thay v√¨ lo·∫°i b·ªè.

```python
# Check if company_name exists
if 'company_name' in df.columns:
    dup_subset = ['job_title', 'company_name', 'city']
    dup_mask = df.duplicated(subset=dup_subset, keep='first')
    df = df[~dup_mask].copy()  # Remove duplicates
else:
    # Flag potential duplicates only
    dup_subset = ['job_title', 'city']
    dup_mask = df.duplicated(subset=dup_subset, keep=False)
    df['is_potential_duplicate'] = dup_mask
```

### K·∫øt qu·∫£
- **67,374 b·∫£n ghi** ƒë∆∞·ª£c g·∫Øn c·ªù l√† potential duplicates
- Kh√¥ng lo·∫°i b·ªè v√¨ thi·∫øu th√¥ng tin company_name ƒë·ªÉ x√°c nh·∫≠n

---

## üö´ B∆Ø·ªöC 6: LO·∫†I B·ªé OUTLIERS L∆Ø∆†NG

### V·∫•n ƒë·ªÅ

M·ªôt s·ªë b·∫£n ghi c√≥ m·ª©c l∆∞∆°ng **c·ª±c k·ª≥ cao** (>500 tri·ªáu VND/th√°ng), ƒë√¢y l√† l·ªói nh·∫≠p li·ªáu ho·∫∑c gi√° tr·ªã ngo·∫°i lai.

### Gi·∫£i ph√°p

√Åp d·ª•ng **ng∆∞·ª°ng d·ª±a tr√™n domain knowledge**:
```python
# L∆∞∆°ng > 500 tri·ªáu VND/th√°ng ƒë∆∞·ª£c coi l√† outlier
salary_extreme = df['salary_max'] > 500
n_outlier = int(salary_extreme.sum())  # = 4
df = df[~salary_extreme].copy()
```

### K·∫øt qu·∫£
- **4 b·∫£n ghi** b·ªã lo·∫°i do l∆∞∆°ng > 500 tri·ªáu VND

---

## üìÇ B∆Ø·ªöC 7: T√ÅCH V√Ä X·ª¨ L√ù JOB FIELDS

### V·∫•n ƒë·ªÅ

C·ªôt `job_fields` ch·ª©a nhi·ªÅu ng√†nh ngh·ªÅ ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y.

### Gi·∫£i ph√°p

T√°ch th√†nh danh s√°ch v√† tr√≠ch xu·∫•t th√¥ng tin:
```python
def split_job_fields(fields_str):
    if pd.isna(fields_str):
        return []
    return [f.strip().lower() for f in str(fields_str).split(',') if f.strip()]

df['job_fields_list'] = df['job_fields'].apply(split_job_fields)
df['job_fields_count'] = df['job_fields_list'].apply(len)
df['job_field_primary'] = df['job_fields_list'].apply(lambda x: x[0] if x else np.nan)
```

### K·∫øt qu·∫£
- `job_fields_list`: Danh s√°ch c√°c ng√†nh ngh·ªÅ (array)
- `job_fields_count`: S·ªë l∆∞·ª£ng ng√†nh ngh·ªÅ li√™n quan
- `job_field_primary`: Ng√†nh ngh·ªÅ ch√≠nh (ƒë·∫ßu ti√™n trong danh s√°ch)

---

## üßÆ B∆Ø·ªöC 8: T·∫†O C√ÅC ƒê·∫∂C TR∆ØNG M·ªöI (DERIVED FEATURES)

### 8.1 L∆∞∆°ng Trung V·ªã

```python
df['salary_median'] = (df['salary_min'] + df['salary_max']) / 2
df['salary_median_imputed'] = (df['salary_min_imputed'] + df['salary_max_imputed']) / 2
```

### 8.2 Ph√¢n V√πng Mi·ªÅn

```python
def classify_region(city):
    if pd.isna(city):
        return 'To√†n qu·ªëc'
    city_lower = str(city).lower()
    
    # Mi·ªÅn B·∫Øc
    north = ['hanoi', 'hai phong', 'bac ninh', 'hai duong', 'hung yen', ...]
    # Mi·ªÅn Trung
    central = ['da nang', 'hue', 'nha trang', 'quang nam', 'binh dinh', ...]
    # Mi·ªÅn Nam
    south = ['ho chi minh', 'binh duong', 'dong nai', 'can tho', 'long an', ...]
    
    for city_name in north:
        if city_name in city_lower:
            return 'Mi·ªÅn B·∫Øc'
    for city_name in central:
        if city_name in city_lower:
            return 'Mi·ªÅn Trung'
    for city_name in south:
        if city_name in city_lower:
            return 'Mi·ªÅn Nam'
    return 'To√†n qu·ªëc'

df['region'] = df['city'].apply(classify_region)
```

### 8.3 S·ªë NƒÉm Kinh Nghi·ªám

```python
def parse_experience(exp_str):
    if pd.isna(exp_str):
        return 0
    exp_lower = str(exp_str).lower()
    
    # Extract numbers using regex
    numbers = re.findall(r'(\d+)', exp_lower)
    if numbers:
        return int(numbers[0])
    
    # Handle text patterns
    if 'kh√¥ng y√™u c·∫ßu' in exp_lower or 'ch∆∞a c√≥' in exp_lower:
        return 0
    return 0

df['exp_years'] = df['experience'].apply(parse_experience)
```

### 8.4 C·∫•p B·∫≠c V·ªã Tr√≠ (ƒê∆°n Gi·∫£n H√≥a)

```python
def simplify_position(pos_level):
    if pd.isna(pos_level):
        return 'Nh√¢n vi√™n'
    pos_lower = str(pos_level).lower()
    
    if any(x in pos_lower for x in ['gi√°m ƒë·ªëc', 'director', 'ceo', 'cto', 'cfo']):
        return 'Gi√°m ƒë·ªëc'
    elif any(x in pos_lower for x in ['qu·∫£n l√Ω', 'manager', 'tr∆∞·ªüng ph√≤ng']):
        return 'Qu·∫£n l√Ω'
    elif any(x in pos_lower for x in ['tr∆∞·ªüng nh√≥m', 'team lead', 'supervisor']):
        return 'Tr∆∞·ªüng nh√≥m'
    elif any(x in pos_lower for x in ['chuy√™n gia', 'expert', 'senior']):
        return 'Chuy√™n gia'
    elif any(x in pos_lower for x in ['th·ª±c t·∫≠p', 'intern']):
        return 'Th·ª±c t·∫≠p sinh'
    else:
        return 'Nh√¢n vi√™n'

df['position_simple'] = df['position_level'].apply(simplify_position)
```

### 8.5 ƒê·∫øm S·ªë K·ªπ NƒÉng

```python
def count_skills(skills_str):
    if pd.isna(skills_str):
        return 0
    return len([s.strip() for s in str(skills_str).split(',') if s.strip()])

df['skill_count'] = df['skills'].apply(count_skills)
```

### 8.6 C√°c Feature Kh√°c

```python
# C√≥ y√™u c·∫ßu ti·∫øng Anh
df['requires_english'] = df['skills'].str.lower().str.contains('english|ti·∫øng anh', na=False).astype(int)

# C√≥ k·ªπ nƒÉng IT
it_keywords = ['python', 'java', 'sql', 'excel', 'javascript', 'c#', 'c++', 'react', 'nodejs']
df['has_tech_skills'] = df['skills'].str.lower().str.contains('|'.join(it_keywords), na=False).astype(int)
```

---

## üìä T·ªîNG K·∫æT QUY TR√åNH

### B·∫£ng T√≥m T·∫Øt C√°c B∆∞·ªõc

| B∆∞·ªõc | M√¥ t·∫£ | S·ªë b·∫£n ghi ·∫£nh h∆∞·ªüng |
|------|-------|---------------------|
| 0 | Normalize text, handle 'nan' strings | T·∫•t c·∫£ |
| 1 | Chu·∫©n h√≥a t√™n th√†nh ph·ªë | 466 ‚Üí 415 unique |
| 2 | Chuy·ªÉn ƒë·ªïi USD ‚Üí VND | 713 b·∫£n ghi |
| 3a | Lo·∫°i b·ªè salary_min > salary_max | -3,495 b·∫£n ghi |
| 3b | Chuy·ªÉn salary = 0 th√†nh NaN | 2,202 b·∫£n ghi |
| 4 | G·∫Øn c·ªù missing salaries, imputation | ~80% d·ªØ li·ªáu |
| 5 | G·∫Øn c·ªù potential duplicates | 67,374 b·∫£n ghi |
| 6 | Lo·∫°i b·ªè outliers l∆∞∆°ng | -4 b·∫£n ghi |
| 7 | T√°ch job_fields th√†nh array | T·∫•t c·∫£ |
| 8 | T·∫°o derived features | T·∫•t c·∫£ |

### C·ªôt M·ªõi ƒê∆∞·ª£c T·∫°o

| T√™n c·ªôt | Ki·ªÉu | M√¥ t·∫£ |
|---------|------|-------|
| `city` | string | T√™n th√†nh ph·ªë ƒë√£ chu·∫©n h√≥a (ti·∫øng Anh) |
| `has_salary` | boolean | True n·∫øu c√≥ th√¥ng tin l∆∞∆°ng |
| `salary_min_imputed` | float | L∆∞∆°ng min ƒë√£ impute b·∫±ng median ng√†nh |
| `salary_max_imputed` | float | L∆∞∆°ng max ƒë√£ impute b·∫±ng median ng√†nh |
| `salary_median` | float | (min + max) / 2 |
| `salary_median_imputed` | float | (min_imputed + max_imputed) / 2 |
| `job_fields_list` | array | Danh s√°ch ng√†nh ngh·ªÅ |
| `job_fields_count` | int | S·ªë l∆∞·ª£ng ng√†nh ngh·ªÅ |
| `job_field_primary` | string | Ng√†nh ngh·ªÅ ch√≠nh |
| `region` | string | V√πng mi·ªÅn (B·∫Øc/Trung/Nam/To√†n qu·ªëc) |
| `exp_years` | int | S·ªë nƒÉm kinh nghi·ªám y√™u c·∫ßu |
| `position_simple` | string | C·∫•p b·∫≠c ƒë√£ ƒë∆°n gi·∫£n h√≥a |
| `skill_count` | int | S·ªë l∆∞·ª£ng k·ªπ nƒÉng y√™u c·∫ßu |
| `requires_english` | int | 1 n·∫øu y√™u c·∫ßu ti·∫øng Anh |
| `has_tech_skills` | int | 1 n·∫øu y√™u c·∫ßu k·ªπ nƒÉng IT |
| `is_potential_duplicate` | boolean | True n·∫øu c√≥ th·ªÉ tr√πng l·∫∑p |

### B√°o C√°o L√†m S·∫°ch (Output)

```
======================================================================
 DATA CLEANING REPORT
======================================================================
  ‚Ä¢ Standardized city names: 466 unique ‚Üí 415 unique
  ‚Ä¢ Converted 713 USD salaries to VND (rate=25,000)
  ‚Ä¢ Removed 3,495 rows: salary_min > salary_max
  ‚Ä¢ Set 2,202 rows with 0 salary fields to NaN
  ‚Ä¢ Flagged 4 rows with no salary info (has_salary=False)
  ‚Ä¢ Created imputed salary columns using industry median
  ‚Ä¢ Limitation: company_name not available; duplicates are flagged (not removed)
  ‚Ä¢ Flagged 67,374 rows as potential duplicates using subset=['job_title', 'city']
  ‚Ä¢ Removed 4 salary outliers (>500M VND)
  ‚Ä¢ Split job_fields into arrays (job_fields_list) and extracted primary field
======================================================================
 Final rows: 81,971 (from 85,470)
 Removed: 3,499 (4.1%)
 Rows with valid salary: 81,967 (100.0%)
 USD converted: 713
======================================================================
```

---

## üí° GHI CH√ö V√Ä H·∫†N CH·∫æ

### C√°c quy·∫øt ƒë·ªãnh thi·∫øt k·∫ø

1. **Ch·ªçn lo·∫°i b·ªè thay v√¨ impute cho salary invalid:** V√¨ salary_min > salary_max l√† l·ªói logic r√µ r√†ng, kh√¥ng th·ªÉ kh√¥i ph·ª•c

2. **G·∫Øn c·ªù thay v√¨ lo·∫°i b·ªè duplicates:** Do thi·∫øu c·ªôt `company_name`, kh√¥ng th·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c tr√πng l·∫∑p

3. **S·ª≠ d·ª•ng median thay v√¨ mean cho imputation:** Median √≠t b·ªã ·∫£nh h∆∞·ªüng b·ªüi outliers trong d·ªØ li·ªáu l∆∞∆°ng (skewed distribution)

4. **Ch·ªçn ng∆∞·ª°ng 500M VND cho outliers:** D·ª±a tr√™n domain knowledge - r·∫•t √≠t v·ªã tr√≠ c√≥ l∆∞∆°ng > 500 tri·ªáu/th√°ng

### H·∫°n ch·∫ø

- Thi·∫øu c·ªôt `company_name` ‚Üí kh√¥ng th·ªÉ x·ª≠ l√Ω duplicates ho√†n to√†n
- Thi·∫øu th√¥ng tin chi ti·∫øt v·ªÅ `job_description` ‚Üí kh√≥ tr√≠ch xu·∫•t th√™m features
- D·ªØ li·ªáu l∆∞∆°ng thi·∫øu nhi·ªÅu (~80%) ‚Üí ·∫£nh h∆∞·ªüng ƒë·∫øn m·ªôt s·ªë ph√¢n t√≠ch
