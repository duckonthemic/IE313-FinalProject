# EDA Plan - Exploratory Data Analysis Chi Ti·∫øt

## üìã T·ªïng quan

**M·ª•c ti√™u**: Bi·∫øn EDA t·ª´ 4 bi·ªÉu ƒë·ªì c∆° b·∫£n th√†nh **"G√≥i ph√¢n t√≠ch xu h∆∞·ªõng vi·ªác l√†m IT"** c√≥ chi·ªÅu s√¢u, tr·∫£ l·ªùi c√°c c√¢u h·ªèi quan tr·ªçng v·ªÅ th·ªã tr∆∞·ªùng vi·ªác l√†m IT t·∫°i Vi·ªát Nam.

**Dataset**: `jobs_master.csv` (3,985 jobs)
- **Source**: Kaggle (1,411 jobs - 35.4%) + GitHub (2,574 jobs - 64.6%)
- **Coverage**: 100% c√≥ 13/19 c·ªôt quan tr·ªçng, 92.7% c√≥ skills, 64.6% c√≥ URL

---

## üéØ C·∫•u tr√∫c EDA - 4 Nh√≥m C√¢u H·ªèi

### **Nh√≥m A ‚Äì C·∫•u tr√∫c d·ªØ li·ªáu (Data Structure Overview)**
*M·ª•c ti√™u: Hi·ªÉu ph√¢n b·ªë c∆° b·∫£n c·ªßa dataset*

### **Nh√≥m B ‚Äì Skills Analysis (Ph√¢n t√≠ch k·ªπ nƒÉng)**
*M·ª•c ti√™u: Kh√°m ph√° skills ph·ªï bi·∫øn v√† must-have cho t·ª´ng category*

### **Nh√≥m C ‚Äì Company & Job Site Analysis (Ph√¢n t√≠ch c√¥ng ty & n·ªÅn t·∫£ng)**
*M·ª•c ti√™u: So s√°nh c√¥ng ty, ngu·ªìn d·ªØ li·ªáu, n·ªÅn t·∫£ng tuy·ªÉn d·ª•ng*

### **Nh√≥m D ‚Äì K·∫øt n·ªëi gi·ªØa Category & City (Geo-Category Analysis)**
*M·ª•c ti√™u: T√¨m m·ªëi quan h·ªá gi·ªØa ƒë·ªãa ƒëi·ªÉm v√† lo·∫°i c√¥ng vi·ªác*

---

## üìä CHI TI·∫æT T·ª™NG NH√ìM

---

## Nh√≥m A ‚Äì C·∫•u tr√∫c d·ªØ li·ªáu (Data Structure Overview)

### A1. Distribution of Job Categories
**C√¢u h·ªèi**: Category n√†o chi·∫øm t·ª∑ l·ªá l·ªõn nh·∫•t trong th·ªã tr∆∞·ªùng IT Vi·ªát Nam?

**C·ªôt s·ª≠ d·ª•ng**: `job_category`

**Bi·ªÉu ƒë·ªì**: **Horizontal Bar Chart** (Top 15 categories)
- X-axis: Job count
- Y-axis: Job category
- Color: Gradient (dark ‚Üí light theo s·ªë l∆∞·ª£ng)
- Sort: Descending by count

**Metric t√≠nh to√°n**:
- Count per category
- Percentage distribution
- Top 3 vs Bottom 3 categories

**Insight k·ª≥ v·ªçng**:
1. ‚úÖ **"Other" s·∫Ω chi·∫øm t·ª∑ l·ªá cao (40.5%)** v√¨ nhi·ªÅu job title kh√¥ng match keywords (ƒë√£ validate trong categorization_rules.md)
2. ‚úÖ **Backend > Fullstack > QA/Tester** (d·ª±a tr√™n ph√¢n t√≠ch hi·ªán t·∫°i: Backend 9.4%, Fullstack 8.7%, QA 8.5%)
3. üîç **Data Science/AI categories th·∫•p** (emerging field, ch∆∞a ph·ªï bi·∫øn r·ªông r√£i)

**Cross-reference**: 
- `docs/categorization_rules.md` - Keyword rules cho classification
- Current distribution: Other 40.5%, Backend 9.4%, Fullstack 8.7%

---

### A2. Distribution of Job Levels
**C√¢u h·ªèi**: Th·ªã tr∆∞·ªùng tuy·ªÉn level n√†o nhi·ªÅu nh·∫•t? Junior hay Senior?

**C·ªôt s·ª≠ d·ª•ng**: `job_level`

**Bi·ªÉu ƒë·ªì**: **Pie Chart** ho·∫∑c **Donut Chart** v·ªõi percentages
- Slices: 5 levels (intern, junior, mid, senior, manager)
- Colors: Sequential palette (light blue ‚Üí dark blue)
- Labels: Count + Percentage

**Metric t√≠nh to√°n**:
- Count per level
- Percentage distribution
- Mid-to-Senior ratio (ki·ªÉm tra th·ªã tr∆∞·ªùng thi√™n v·ªÅ experienced hay entry-level)

**Insight k·ª≥ v·ªçng**:
1. ‚úÖ **Mid-level chi·∫øm ƒëa s·ªë (~65.7%)** - ƒê√£ validate trong categorization_rules.md
2. ‚úÖ **Senior level cao (23.3%)** - Th·ªã tr∆∞·ªùng c·∫ßn ng∆∞·ªùi c√≥ kinh nghi·ªám
3. üîç **Junior + Intern th·∫•p (<8%)** - √çt v·ªã tr√≠ entry-level?

**C√¢u h·ªèi follow-up** (cho EDA phase 2):
- Mid-level nhi·ªÅu ·ªü category n√†o? (Backend c√≥ nhi·ªÅu mid h∆°n QA kh√¥ng?)
- Senior nhi·ªÅu ·ªü city n√†o? (HCM vs HN)

**Cross-reference**: 
- `docs/categorization_rules.md` - Job level keywords v√† priority
- Current distribution: mid 65.7%, senior 23.3%, junior 5.0%

---

### A3. Distribution of Cities
**C√¢u h·ªèi**: Job t·∫≠p trung ·ªü th√†nh ph·ªë n√†o? HCM vs HN vs Remote?

**C·ªôt s·ª≠ d·ª•ng**: `city`

**Bi·ªÉu ƒë·ªì**: **Vertical Bar Chart** (Top 10 cities)
- X-axis: City name
- Y-axis: Job count
- Color: Different color per city (use distinctive palette)
- Sort: Descending by count

**Metric t√≠nh to√°n**:
- Count per city
- Percentage distribution
- HCM-to-HN ratio
- Remote job percentage

**Insight k·ª≥ v·ªçng**:
1. üîç **Ho Chi Minh >> Ha Noi** (HCM l√† tech hub l·ªõn nh·∫•t)
2. üîç **Da Nang ·ªü v·ªã tr√≠ th·ª© 3** (hub m·ªõi n·ªïi)
3. üîç **Remote jobs tƒÉng** (trend sau COVID)
4. üîç **Other cities < 5%** (job t·∫≠p trung ·ªü 2-3 th√†nh ph·ªë ch√≠nh)

**C√¢u h·ªèi follow-up**:
- Remote jobs thu·ªôc category n√†o? (Backend/Frontend ph√π h·ª£p remote h∆°n QA?)

**Cross-reference**: 
- `docs/schema.md` - City normalization rules
- `data/reference/city_province_mapping.csv` - 90+ patterns normalized

---

### A4. Data Completeness Heatmap (NEW)
**C√¢u h·ªèi**: C·ªôt n√†o c√≥ d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß? C·ªôt n√†o c√≤n thi·∫øu?

**C·ªôt s·ª≠ d·ª•ng**: All 19 columns

**Bi·ªÉu ƒë·ªì**: **Heatmap** showing data coverage
- X-axis: Columns (19 columns)
- Y-axis: Single row (data coverage)
- Color: Green (100%) ‚Üí Yellow (50%) ‚Üí Red (0%)
- Annotation: Percentage in each cell

**Metric t√≠nh to√°n**:
- For each column: `non_null_count / total_count * 100`
- Identify columns with 0% data (salary fields)
- Identify columns with partial data (skills 92.7%, url 64.6%)

**Insight k·ª≥ v·ªçng**:
1. ‚úÖ **13/19 c·ªôt c√≥ 100% data** (job_title, company_name, city, job_level, job_category, etc.)
2. ‚úÖ **Skills: 92.7% coverage** (good for skills analysis)
3. ‚úÖ **URL: 64.6% coverage** (ch·ªâ GitHub c√≥, Kaggle kh√¥ng c√≥)
4. ‚úÖ **Salary: 0% coverage** (c·∫£ 4 c·ªôt salary ƒë·ªÅu NULL)

**√ù nghƒ©a**: X√°c ƒë·ªãnh columns n√†o reliable cho analysis, columns n√†o c·∫ßn skip

**Cross-reference**: 
- `docs/schema.md` - Full column documentation
- `docs/STAGE_2_SUMMARY.md` - Task 2.2 salary clarification

---

## Nh√≥m B ‚Äì Skills Analysis (Ph√¢n t√≠ch k·ªπ nƒÉng)

### B1. Top 20 Most Popular Skills
**C√¢u h·ªèi**: Skill n√†o ƒë∆∞·ª£c y√™u c·∫ßu nhi·ªÅu nh·∫•t trong job IT Vi·ªát Nam?

**C·ªôt s·ª≠ d·ª•ng**: `skills` (92.7% coverage)

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# Skills are pipe-separated: "python|django|postgresql"
skills_list = df['skills'].dropna().str.split('|')
all_skills = [skill.strip().lower() for sublist in skills_list for skill in sublist]
skill_counts = pd.Series(all_skills).value_counts().head(20)
```

**Bi·ªÉu ƒë·ªì**: **Horizontal Bar Chart** (Top 20 skills)
- X-axis: Frequency count
- Y-axis: Skill name
- Color: Gradient by frequency (hot colormap)
- Sort: Descending by count

**Metric t√≠nh to√°n**:
- Frequency count per skill
- Percentage of jobs mentioning skill
- Top 5 skills dominating market

**Insight k·ª≥ v·ªçng**:
1. üîç **JavaScript/TypeScript/React ph·ªï bi·∫øn** (web development dominant)
2. üîç **Python xu·∫•t hi·ªán nhi·ªÅu** (backend + data + AI)
3. üîç **Java/Spring ph·ªï bi·∫øn** (enterprise applications)
4. üîç **SQL/Database skills high** (backend fundamental)
5. üîç **Docker/Kubernetes/AWS** (DevOps trend)

**C√¢u h·ªèi follow-up**:
- Skill n√†o ƒëang "hot" (tƒÉng tr∆∞·ªüng nhanh)?
- Skill n√†o k·∫øt h·ª£p v·ªõi nhau? (React + Node? Python + Django?)

---

### B2. Must-Have Skills Per Category (Category-Specific Skills)
**C√¢u h·ªèi**: V·ªõi m·ªói category (Backend, Frontend, QA, Data...), skill n√†o l√† "must-have"?

**C·ªôt s·ª≠ d·ª•ng**: `job_category`, `skills`

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# For each category, extract top skills
for category in ['Backend Developer', 'Frontend Developer', 'QA/Tester', 
                  'Data Engineer', 'Mobile Developer', 'DevOps Engineer']:
    cat_skills = df[df['job_category'] == category]['skills'].dropna()
    # Get top 10 skills for this category
```

**Bi·ªÉu ƒë·ªì**: **Grouped Horizontal Bar Chart** ho·∫∑c **Facet Plot**
- Option 1: Facet grid (6 subplots for top 6 categories)
- Option 2: Single chart v·ªõi colors per category
- X-axis: Skill frequency
- Y-axis: Skill name
- Color: Different color per category

**Metric t√≠nh to√°n**:
- Top 10 skills per category
- Skill penetration rate: `jobs_with_skill / total_jobs_in_category`
- "Exclusive skills" (skills ch·ªâ c√≥ trong 1 category)

**Insight k·ª≥ v·ªçng**:

**Backend Developer**:
- üîç Must-have: Java, Python, Node.js, Spring Boot, PostgreSQL, MySQL, Docker
- üîç Framework: Django, Laravel, .NET Core

**Frontend Developer**:
- üîç Must-have: React, Vue, Angular, JavaScript, TypeScript, HTML/CSS
- üîç Tools: Webpack, Redux, Next.js

**QA/Tester**:
- üîç Must-have: Selenium, Jira, Postman, automation testing
- üîç Languages: Python (test scripts), Java (test frameworks)

**Data Engineer**:
- üîç Must-have: Python, SQL, Spark, Kafka, Airflow, ETL
- üîç Cloud: AWS, GCP, Azure

**Mobile Developer**:
- üîç Must-have: React Native, Flutter, Swift, Kotlin, iOS, Android

**DevOps Engineer**:
- üîç Must-have: Docker, Kubernetes, Jenkins, CI/CD, AWS, Terraform, Ansible

**C√¢u h·ªèi follow-up**:
- Skills n√†o overlap gi·ªØa c√°c categories? (Python trong Backend vs Data)
- Skills "unicorn" (hi·∫øm, ch·ªâ 1 category c·∫ßn)?

---

### B3. Skills Co-occurrence Matrix (Advanced)
**C√¢u h·ªèi**: Skills n√†o th∆∞·ªùng ƒëi c√πng nhau? (React + Node? Python + Django?)

**C·ªôt s·ª≠ d·ª•ng**: `skills`

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# Create co-occurrence matrix
from itertools import combinations
# For each job, count skill pairs
skill_pairs = []
for skills in df['skills'].dropna():
    skills_list = [s.strip().lower() for s in skills.split('|')]
    skill_pairs.extend(list(combinations(skills_list, 2)))
# Count frequency of pairs
```

**Bi·ªÉu ƒë·ªì**: **Heatmap** (Top 15 skills √ó Top 15 skills)
- X-axis: Skill A
- Y-axis: Skill B
- Color: Co-occurrence frequency (dark = high co-occurrence)
- Annotation: Counts in cells

**Metric t√≠nh to√°n**:
- Co-occurrence count for each skill pair
- Support: `P(A and B)` - How often both appear together
- Confidence: `P(B|A)` - If job has A, probability of having B

**Insight k·ª≥ v·ªçng**:
1. üîç **React + TypeScript** (modern frontend stack)
2. üîç **Python + Django/Flask** (Python backend combo)
3. üîç **Java + Spring** (enterprise Java stack)
4. üîç **Docker + Kubernetes** (containerization stack)
5. üîç **AWS + Terraform** (cloud infrastructure)

**·ª®ng d·ª•ng**: 
- Recommendation: "N·∫øu b·∫°n bi·∫øt React, n√™n h·ªçc th√™m TypeScript/Redux"
- Job matching: Skills combos for better matches

---

### B4. Skills Diversity by Category (Box Plot)
**C√¢u h·ªèi**: Category n√†o y√™u c·∫ßu nhi·ªÅu skills nh·∫•t? Backend hay QA?

**C·ªôt s·ª≠ d·ª•ng**: `job_category`, `skills`

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# Count number of skills per job
df['skill_count'] = df['skills'].str.split('|').str.len()
# Group by category, get distribution
```

**Bi·ªÉu ƒë·ªì**: **Box Plot** (Skills count distribution per category)
- X-axis: Job category
- Y-axis: Number of skills required
- Box: Q1, Median, Q3
- Whiskers: Min, Max
- Outliers: Jobs with unusually many/few skills

**Metric t√≠nh to√°n**:
- Mean skills per category
- Median skills per category
- Max skills (most demanding jobs)
- Min skills (entry-level?)

**Insight k·ª≥ v·ªçng**:
1. üîç **Backend/Fullstack y√™u c·∫ßu nhi·ªÅu skills nh·∫•t** (database + framework + DevOps)
2. üîç **QA y√™u c·∫ßu √≠t skills h∆°n** (focused on testing tools)
3. üîç **Data Engineer/DevOps cao** (multi-tool environments)
4. üîç **Junior jobs: √≠t skills, Senior jobs: nhi·ªÅu skills**

**C√¢u h·ªèi follow-up**:
- Job n√†o y√™u c·∫ßu nhi·ªÅu skills nh·∫•t? (specific job_id)
- C√≥ correlation gi·ªØa s·ªë skills v√† job_level kh√¥ng?

---

## Nh√≥m C ‚Äì Company & Job Site Analysis (Ph√¢n t√≠ch c√¥ng ty & n·ªÅn t·∫£ng)

### C1. Top 20 Companies Hiring Most
**C√¢u h·ªèi**: C√¥ng ty n√†o tuy·ªÉn nhi·ªÅu job IT nh·∫•t?

**C·ªôt s·ª≠ d·ª•ng**: `company_name`

**Bi·ªÉu ƒë·ªì**: **Horizontal Bar Chart** (Top 20 companies)
- X-axis: Number of job postings
- Y-axis: Company name
- Color: Gradient (or industry-based if available)
- Sort: Descending by count

**Metric t√≠nh to√°n**:
- Job count per company
- Percentage of total jobs
- Top 5 companies vs Rest

**Insight k·ª≥ v·ªçng**:
1. üîç **Big tech companies** (FPT Software, Viettel, VNPT) tuy·ªÉn nhi·ªÅu
2. üîç **Outsourcing companies** (KMS, NashTech, Luxoft) high volume
3. üîç **Startups** (n·∫øu c√≥) - smaller counts, distributed
4. üîç **Top 20 chi·∫øm ~30-40% total jobs** (t·∫≠p trung v√†o big players)

**C√¢u h·ªèi follow-up**:
- C√¥ng ty n√†o tuy·ªÉn level n√†o? (FPT nhi·ªÅu junior? KMS nhi·ªÅu senior?)
- C√¥ng ty n√†o tuy·ªÉn category g√¨? (Viettel nhi·ªÅu Backend? VNG nhi·ªÅu Game Dev?)

---

### C2. Job Distribution by Source Dataset
**C√¢u h·ªèi**: Kaggle vs GitHub - ngu·ªìn n√†o ƒë√≥ng g√≥p nhi·ªÅu h∆°n? C√≥ kh√°c bi·ªát g√¨?

**C·ªôt s·ª≠ d·ª•ng**: `source_dataset` (kaggle_itviec vs github_it_job_posting)

**Bi·ªÉu ƒë·ªì 1**: **Pie Chart** (Simple count comparison)
- Slices: 2 sources (Kaggle 35.4%, GitHub 64.6%)

**Bi·ªÉu ƒë·ªì 2**: **Stacked Bar Chart** (Category distribution by source)
- X-axis: Job category
- Y-axis: Job count
- Stacks: 2 colors (Kaggle vs GitHub)
- Compare: Which categories dominated by which source?

**Metric t√≠nh to√°n**:
- Count per source
- Category distribution per source
- Level distribution per source

**Insight k·ª≥ v·ªçng**:
1. ‚úÖ **GitHub ƒë√≥ng g√≥p nhi·ªÅu h∆°n (64.6%)** - ƒê√£ bi·∫øt t·ª´ deduplication metrics
2. üîç **Kaggle (ITViec) c√≥ nhi·ªÅu mid-level jobs** (ITViec popular cho local market)
3. üîç **GitHub c√≥ nhi·ªÅu senior jobs** (LinkedIn/TopCV trong GitHub data)
4. üîç **Overlap companies: ~500 companies** (t·ª´ deduplication analysis)

**Cross-reference**: 
- `docs/pipeline_overview.md` - Deduplication section
- 528 duplicates removed (11.7% overlap)

---

### C3. Job Site Comparison (ITViec vs LinkedIn vs TopCV)
**C√¢u h·ªèi**: N·ªÅn t·∫£ng n√†o ƒëƒÉng lo·∫°i job g√¨? ITViec nhi·ªÅu Backend? LinkedIn nhi·ªÅu Senior?

**C·ªôt s·ª≠ d·ª•ng**: `job_site` (itviec, LinkedIn, ITViec, TopCV)

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# Normalize job_site (itviec vs ITViec)
df['job_site_clean'] = df['job_site'].str.lower().str.strip()
```

**Bi·ªÉu ƒë·ªì 1**: **Grouped Bar Chart** (Job count by site)
- X-axis: Job site
- Y-axis: Job count
- Show top 3-4 sites

**Bi·ªÉu ƒë·ªì 2**: **Stacked Bar Chart** (Category distribution by job site)
- X-axis: Job site
- Y-axis: Percentage (normalized to 100% per site)
- Stacks: Top 8 categories
- Compare: ITViec = Backend-heavy? LinkedIn = Senior-heavy?

**Bi·ªÉu ƒë·ªì 3**: **Grouped Bar Chart** (Level distribution by job site)
- X-axis: Job site
- Y-axis: Count
- Groups: 5 levels (intern, junior, mid, senior, manager)

**Metric t√≠nh to√°n**:
- Count per job_site
- Category distribution per site (percentage)
- Level distribution per site (percentage)
- Average skills_count per site

**Insight k·ª≥ v·ªçng**:
1. üîç **ITViec**: Many mid-level, Backend/Frontend jobs (local focus)
2. üîç **LinkedIn**: More senior-level, international companies
3. üîç **TopCV**: Mix, potentially more entry-level (broader audience)

**Cross-reference**: 
- `docs/column_mapping.md` - job_site mapping rules
- Kaggle ‚Üí always `itviec`, GitHub ‚Üí preserve original `site`

---

### C4. Companies with Most Diverse Job Postings
**C√¢u h·ªèi**: C√¥ng ty n√†o tuy·ªÉn ƒëa d·∫°ng nh·∫•t (nhi·ªÅu category, nhi·ªÅu level)?

**C·ªôt s·ª≠ d·ª•ng**: `company_name`, `job_category`, `job_level`

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# For each company, count unique categories and levels
company_diversity = df.groupby('company_name').agg({
    'job_category': 'nunique',
    'job_level': 'nunique',
    'job_id': 'count'
}).rename(columns={'job_id': 'total_jobs'})
# Diversity score = (unique_categories + unique_levels) / 2
company_diversity['diversity_score'] = (
    company_diversity['job_category'] + company_diversity['job_level']
) / 2
```

**Bi·ªÉu ƒë·ªì**: **Scatter Plot** (Diversity vs Volume)
- X-axis: Total jobs posted
- Y-axis: Diversity score (unique categories + levels)
- Size: Bubble size = total jobs
- Color: Gradient by diversity score
- Label: Top 10 companies

**Metric t√≠nh to√°n**:
- Unique categories per company
- Unique levels per company
- Diversity score (combined metric)
- Top 10 most diverse companies

**Insight k·ª≥ v·ªçng**:
1. üîç **Big companies (FPT, Viettel) = high diversity** (tuy·ªÉn all categories, all levels)
2. üîç **Small companies = low diversity** (focus on 1-2 categories)
3. üîç **Outliers**: Nhi·ªÅu jobs nh∆∞ng √≠t diversity (ch·ªâ tuy·ªÉn 1 role)

**·ª®ng d·ª•ng**: Identify companies good for career growth (nhi·ªÅu roles kh√°c nhau)

---

## Nh√≥m D ‚Äì K·∫øt n·ªëi gi·ªØa Category & City (Geo-Category Analysis)

### D1. Category Distribution by City (Heatmap)
**C√¢u h·ªèi**: Th√†nh ph·ªë n√†o m·∫°nh v·ªÅ Backend? Th√†nh ph·ªë n√†o nhi·ªÅu Data Engineer?

**C·ªôt s·ª≠ d·ª•ng**: `city`, `job_category`

**Bi·ªÉu ƒë·ªì**: **Heatmap** (City √ó Category)
- X-axis: Job category (Top 10 categories)
- Y-axis: City (Top 8 cities: HCM, HN, Da Nang, Remote, etc.)
- Color: Job count (dark = high concentration)
- Annotation: Count in each cell

**Metric t√≠nh to√°n**:
- Job count for each (city, category) pair
- Percentage of category jobs in each city
- Dominant category per city

**Insight k·ª≥ v·ªçng**:
1. üîç **Ho Chi Minh**: Strong in Backend, Fullstack, QA (tech hub)
2. üîç **Ha Noi**: Strong in Data Engineer, AI/ML (research + tech companies)
3. üîç **Da Nang**: Growing in Backend, Frontend (emerging hub)
4. üîç **Remote**: High in Backend, DevOps (remote-friendly roles)
5. üîç **Other cities**: Low job counts, scattered categories

**C√¢u h·ªèi follow-up**:
- City n√†o c√≥ "specialty"? (HN = Data, HCM = Backend)
- Remote jobs: Which categories are most remote-friendly?

---

### D2. Level Distribution by City (Stacked Bar Chart)
**C√¢u h·ªèi**: HCM vs HN - th√†nh ph·ªë n√†o tuy·ªÉn senior nhi·ªÅu h∆°n?

**C·ªôt s·ª≠ d·ª•ng**: `city`, `job_level`

**Bi·ªÉu ƒë·ªì**: **Stacked Bar Chart** (100% stacked)
- X-axis: City (Top 6 cities)
- Y-axis: Percentage (normalized to 100% per city)
- Stacks: 5 levels (intern, junior, mid, senior, manager)
- Colors: Sequential palette (light ‚Üí dark = intern ‚Üí manager)

**Metric t√≠nh to√°n**:
- Level distribution per city (percentage)
- Mid-to-Senior ratio per city
- Which city has most entry-level jobs?

**Insight k·ª≥ v·ªçng**:
1. üîç **Ha Noi**: More senior/manager roles (HQ of big corps)
2. üîç **Ho Chi Minh**: More mid-level roles (high volume, diverse)
3. üîç **Da Nang**: More junior/mid roles (growing market, training hub)
4. üîç **Remote**: Skew toward senior (trust-based remote work)

**Cross-reference**: 
- Compare v·ªõi A2 (overall level distribution)
- Identify cities best for entry-level vs experienced candidates

---

### D3. Top Skills by City (Facet Grid)
**C√¢u h·ªèi**: HCM c·∫ßn skill g√¨? HN c·∫ßn skill g√¨ kh√°c?

**C·ªôt s·ª≠ d·ª•ng**: `city`, `skills`

**Bi·ªÉu ƒë·ªì**: **Facet Grid** (4-6 subplots for top cities)
- Subplots: Ha Noi, Ho Chi Minh, Da Nang, Remote (4 plots)
- Each subplot: Horizontal bar chart (Top 10 skills for that city)
- X-axis: Skill frequency
- Y-axis: Skill name
- Color: Same color per city (for consistency)

**Metric t√≠nh to√°n**:
- Top 10 skills per city
- Skill penetration: `skill_count / total_jobs_in_city`
- Common skills across all cities vs city-specific skills

**Insight k·ª≥ v·ªçng**:
1. üîç **Ho Chi Minh**: JavaScript, React, Node, Java (web dev focus)
2. üîç **Ha Noi**: Python, AWS, Data skills (data + cloud focus)
3. üîç **Da Nang**: React, Vue, Frontend skills (outsourcing focus)
4. üîç **Remote**: Docker, Kubernetes, Backend (DevOps/Backend friendly)

**·ª®ng d·ª•ng**: 
- Job seekers: "N·∫øu b·∫°n bi·∫øt Python, n√™n t√¨m vi·ªác ·ªü HN"
- Companies: "HCM thi·∫øu Data Engineer, c∆° h·ªôi tuy·ªÉn"

---

### D4. Category-City Concentration Index (Advanced)
**C√¢u h·ªèi**: Category n√†o "t·∫≠p trung" nh·∫•t v√†o 1 th√†nh ph·ªë? (Specialization index)

**C·ªôt s·ª≠ d·ª•ng**: `city`, `job_category`

**X·ª≠ l√Ω d·ªØ li·ªáu**:
```python
# Calculate Herfindahl Index (concentration measure)
# For each category, calculate: sum((city_share)^2)
# High index = concentrated in 1 city
# Low index = distributed across cities
```

**Bi·ªÉu ƒë·ªì**: **Horizontal Bar Chart** (Concentration index per category)
- X-axis: Concentration index (0 to 1)
- Y-axis: Job category
- Color: Gradient (red = high concentration, green = distributed)
- Sort: Descending by index

**Metric t√≠nh to√°n**:
- Herfindahl Index per category: `HHI = sum((share_i)^2)`
- Which category most concentrated? (e.g., Data Engineer in HN)
- Which category most distributed? (e.g., Backend everywhere)

**Insight k·ª≥ v·ªçng**:
1. üîç **Data Engineer/AI jobs**: High concentration (mostly HN)
2. üîç **Backend Developer**: Low concentration (distributed HCM/HN/DN)
3. üîç **Game Developer**: High concentration (specific hubs)
4. üîç **QA/Tester**: Medium concentration (follows Backend)

**·ª®ng d·ª•ng**: 
- Identify specialized cities (HN = Data hub)
- Identify generalist cities (HCM = all categories)

---

## üìä SUMMARY TABLE - ALL EDA QUESTIONS

| Nh√≥m | ID | C√¢u h·ªèi | C·ªôt s·ª≠ d·ª•ng | Bi·ªÉu ƒë·ªì | Insight k·ª≥ v·ªçng |
|------|----|---------|--------------|---------|--------------------|
| **A** | A1 | Category n√†o chi·∫øm t·ª∑ l·ªá l·ªõn nh·∫•t? | `job_category` | Horizontal Bar | Other 40.5%, Backend 9.4%, Fullstack 8.7% |
| **A** | A2 | Th·ªã tr∆∞·ªùng tuy·ªÉn level n√†o nhi·ªÅu nh·∫•t? | `job_level` | Pie/Donut | Mid 65.7%, Senior 23.3% |
| **A** | A3 | Job t·∫≠p trung ·ªü th√†nh ph·ªë n√†o? | `city` | Vertical Bar | HCM >> HN >> Da Nang |
| **A** | A4 | C·ªôt n√†o c√≥ d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß? | All 19 columns | Heatmap | 13/19 c·ªôt 100%, skills 92.7%, salary 0% |
| **B** | B1 | Skill n√†o ph·ªï bi·∫øn nh·∫•t? | `skills` | Horizontal Bar | JS/React/Python/Java/SQL top 5 |
| **B** | B2 | Must-have skills per category? | `job_category`, `skills` | Grouped/Facet | Backend‚ÜíJava/Python, Frontend‚ÜíReact/Vue |
| **B** | B3 | Skills n√†o ƒëi c√πng nhau? | `skills` | Heatmap | React+TypeScript, Python+Django, Docker+K8s |
| **B** | B4 | Category n√†o y√™u c·∫ßu nhi·ªÅu skills nh·∫•t? | `job_category`, `skills` | Box Plot | Backend/Fullstack nhi·ªÅu, QA √≠t |
| **C** | C1 | C√¥ng ty n√†o tuy·ªÉn nhi·ªÅu nh·∫•t? | `company_name` | Horizontal Bar | FPT, Viettel, KMS top |
| **C** | C2 | Kaggle vs GitHub - kh√°c bi·ªát? | `source_dataset`, `job_category` | Pie + Stacked Bar | GitHub 64.6%, Kaggle 35.4% |
| **C** | C3 | ITViec vs LinkedIn vs TopCV? | `job_site`, `job_category`, `job_level` | Grouped + Stacked | ITViec mid-level, LinkedIn senior |
| **C** | C4 | C√¥ng ty n√†o tuy·ªÉn ƒëa d·∫°ng nh·∫•t? | `company_name`, `job_category`, `job_level` | Scatter | Big companies high diversity |
| **D** | D1 | Th√†nh ph·ªë n√†o m·∫°nh v·ªÅ category n√†o? | `city`, `job_category` | Heatmap | HCM=Backend, HN=Data |
| **D** | D2 | HCM vs HN - level distribution? | `city`, `job_level` | Stacked Bar 100% | HN more senior, HCM more mid |
| **D** | D3 | Top skills by city? | `city`, `skills` | Facet Grid | HCM=JS/React, HN=Python/AWS |
| **D** | D4 | Category n√†o t·∫≠p trung v√†o 1 city? | `city`, `job_category` | Horizontal Bar | Data Engineer concentrated in HN |

**T·ªïng s·ªë**: **16 c√¢u h·ªèi EDA**, **4 nh√≥m**, **16 bi·ªÉu ƒë·ªì ch√≠nh**

---

## üé® Visualization Guidelines

### Color Palettes
- **Categories**: Use `tab10` or `Set3` (distinctive colors for 13 categories)
- **Levels**: Sequential blue (`Blues_r`) - intern (light) ‚Üí manager (dark)
- **Cities**: Qualitative palette (`Paired` or `Set2`)
- **Heatmaps**: `YlOrRd` (yellow-orange-red) or `viridis` (perceptually uniform)

### Chart Styling
- **Font**: Use `Arial` or `Helvetica`, size 10-12pt
- **Title**: Bold, size 14pt, clear question
- **Axis labels**: Clear units (count, percentage, etc.)
- **Legend**: Outside plot area (right side), sorted by value
- **Grid**: Light gray, only major gridlines
- **Annotations**: Add percentages for top 3-5 items

### Figure Size Standards
- **Single chart**: 10√ó6 inches
- **Facet grid (2√ó2)**: 12√ó10 inches
- **Heatmap**: 12√ó8 inches (wide for readability)
- **Resolution**: 300 DPI for publication quality

---

## üîÑ Implementation Roadmap

### Phase 1: Basic Structure (Nh√≥m A)
**Timeline**: 1-2 hours
**Tasks**:
1. ‚úÖ Load `jobs_master.csv`
2. ‚úÖ Create 4 basic charts (A1-A4)
3. ‚úÖ Validate distributions against documented stats
4. ‚úÖ Add titles, labels, legends

**Deliverable**: Notebook section "Nh√≥m A - Data Structure Overview" v·ªõi 4 bi·ªÉu ƒë·ªì

---

### Phase 2: Skills Analysis (Nh√≥m B)
**Timeline**: 2-3 hours
**Tasks**:
1. Parse `skills` column (split by `|`, lowercase, strip)
2. Create B1 (Top 20 skills bar chart)
3. Create B2 (Must-have skills per category - 6 facets)
4. Create B3 (Co-occurrence heatmap - advanced)
5. Create B4 (Skills diversity box plot)

**Challenges**:
- Skills data 92.7% coverage (292 jobs missing skills)
- Need to handle NULL/empty skills gracefully
- Co-occurrence matrix can be large (need to filter top skills only)

**Deliverable**: Notebook section "Nh√≥m B - Skills Analysis" v·ªõi 4 bi·ªÉu ƒë·ªì

---

### Phase 3: Company & Job Site (Nh√≥m C)
**Timeline**: 2-3 hours
**Tasks**:
1. Create C1 (Top 20 companies bar chart)
2. Create C2 (Source comparison: pie + stacked bar)
3. Create C3 (Job site comparison: 3 charts)
4. Create C4 (Company diversity scatter plot)

**Challenges**:
- Company name normalization (FPT vs FPT Software?)
- Job site normalization (itviec vs ITViec)
- Source comparison needs clear interpretation

**Deliverable**: Notebook section "Nh√≥m C - Company & Job Site Analysis" v·ªõi 7 bi·ªÉu ƒë·ªì

---

### Phase 4: Geo-Category Analysis (Nh√≥m D)
**Timeline**: 2-3 hours
**Tasks**:
1. Create D1 (City √ó Category heatmap)
2. Create D2 (Level by city stacked bar)
3. Create D3 (Top skills by city facet grid)
4. Create D4 (Concentration index - advanced)

**Challenges**:
- Heatmap can be sparse (many city-category combos have 0 jobs)
- Need to filter to top 8 cities and top 10 categories for clarity
- Concentration index calculation (Herfindahl Index)

**Deliverable**: Notebook section "Nh√≥m D - Geo-Category Analysis" v·ªõi 4 bi·ªÉu ƒë·ªì

---

### Phase 5: Insights Summary & Report
**Timeline**: 1 hour
**Tasks**:
1. Write markdown summary for each nh√≥m
2. Compare expected insights vs actual results
3. Highlight surprising findings (if any)
4. Create final summary table (all metrics)
5. Export key charts as PNG/SVG

**Deliverable**: 
- Notebook section "EDA Summary & Key Insights"
- Folder `outputs/eda_charts/` v·ªõi all PNG exports

---

## üìà Expected Outputs

### After EDA Completion:

**1. Jupyter Notebook**:
- File: `vietnam_it_jobs_merge_analysis.ipynb` (updated)
- Sections:
  - Nh√≥m A: Data Structure (4 charts)
  - Nh√≥m B: Skills Analysis (4 charts)
  - Nh√≥m C: Company & Job Site (7 charts)
  - Nh√≥m D: Geo-Category Analysis (4 charts)
  - Summary & Insights (markdown + table)
- **Total**: 19 charts, ~200 lines of markdown insights

**2. Chart Exports** (optional):
- Folder: `outputs/eda_charts/`
- Files: `A1_category_distribution.png`, `B1_top_skills.png`, etc.
- Format: PNG (300 DPI) or SVG (vector)

**3. Insights Report** (optional):
- File: `docs/eda_insights.md`
- Summary of all findings
- Compare expected vs actual insights
- Recommendations for next steps

---

## üîó Cross-References

### Related Documentation:
- **Schema**: `docs/schema.md` - Column definitions, data coverage
- **Categorization**: `docs/categorization_rules.md` - Job level/category rules
- **Deduplication**: `docs/pipeline_overview.md` - Source merge strategy
- **City Mapping**: `data/reference/city_province_mapping.csv` - 90+ patterns
- **Master Data**: `data/final/jobs_master.csv` - 3,985 jobs

### Key Statistics to Reference:
- Total jobs: 3,985
- Sources: Kaggle 35.4%, GitHub 64.6%
- Cities: 9 unique (HCM, HN, DN, Remote, etc.)
- Categories: 13 categories (Other 40.5%, Backend 9.4%)
- Levels: 5 levels (mid 65.7%, senior 23.3%)
- Skills coverage: 92.7% (3,693/3,985 jobs)
- Companies: 1,901 unique

---

## üéØ Success Criteria

### EDA is considered COMPLETE when:
1. ‚úÖ All 16 questions answered with charts
2. ‚úÖ All 4 nh√≥m (A-D) documented in notebook
3. ‚úÖ Expected insights validated (or explained if different)
4. ‚úÖ Charts have proper titles, labels, legends
5. ‚úÖ Markdown summaries for each nh√≥m
6. ‚úÖ Key findings highlighted (top 3-5 per nh√≥m)
7. ‚úÖ Cross-checked against documentation (schema, categorization, dedup)

### Bonus (Optional):
- üìä Interactive charts (Plotly) instead of static (Matplotlib)
- üì§ Export charts as PNG/SVG for reports
- üìù Create `docs/eda_insights.md` summary report
- üîÑ Add code comments explaining non-obvious calculations

---

## üí° Future Enhancements (Post-EDA)

### After completing basic EDA, consider:

**1. Temporal Analysis** (if posted_date becomes available):
- Job posting trends over time
- Seasonal patterns (which months have most jobs?)
- Category growth rates (which categories growing fast?)

**2. Salary Analysis** (if salary data becomes available):
- Salary by category, level, city
- Skills that pay most
- Company salary ranges

**3. Text Analysis on job_description**:
- Word clouds per category
- Required vs preferred skills (from description text)
- Soft skills mentions (communication, teamwork)

**4. Network Analysis**:
- Company-skill networks (which companies use which skills?)
- Skill-skill networks (which skills cluster together?)
- Category-city networks (bipartite graph)

**5. Predictive Modeling** (already in pipeline):
- Use EDA insights to improve feature engineering
- Feature importance from EDA (which features matter most?)

---

## üìù Notes & Considerations

### Data Quality Notes:
1. **Skills coverage 92.7%**: 292 jobs have no skills data
   - Handle gracefully in B1-B4 (use `.dropna()`)
   - Document impact in insights (e.g., "Based on 3,693 jobs with skills data")

2. **Job site normalization**: `itviec` vs `ITViec`
   - Normalize to lowercase before analysis
   - Document in C3 insights

3. **Company name variations**: 
   - `FPT Software` vs `FPT Software Company Limited`
   - Keep as-is (already normalized in master data)
   - If variations exist, document in C1/C4

4. **Category "Other" high (40.5%)**:
   - Expected (documented in categorization_rules.md)
   - Mention in insights: "Many Vietnamese titles, non-tech roles, specialized roles"

### Visualization Best Practices:
1. **Always sort charts** (descending for bar charts)
2. **Limit to top N** (top 10-20 to avoid clutter)
3. **Add percentages** (not just counts) for context
4. **Use consistent colors** across related charts
5. **Annotate interesting findings** (arrows, text boxes)

### Interpretation Guidelines:
1. **Compare with expectations**: Use "Insight k·ª≥ v·ªçng" as baseline
2. **Explain surprises**: If results differ, investigate why
3. **Cross-validate**: Check against documentation (schema, categorization)
4. **Avoid over-interpretation**: Correlation ‚â† causation
5. **Document limitations**: Missing data, normalization issues, etc.

---

## ‚úÖ Checklist - EDA Plan Complete

- [x] Define 4 nh√≥m c√¢u h·ªèi (A, B, C, D)
- [x] List 16 specific questions with columns, charts, insights
- [x] Document expected insights per question
- [x] Provide implementation roadmap (5 phases)
- [x] Define success criteria
- [x] Add visualization guidelines (colors, styling, sizes)
- [x] Cross-reference with existing documentation
- [x] Include data quality notes and considerations
- [x] Create summary table (16 questions overview)
- [x] Document future enhancements (post-EDA)

---

**Status**: ‚úÖ **EDA Plan HO√ÄN TH√ÄNH**  
**File**: `docs/eda_plan.md`  
**Next Step**: Implement EDA in notebook (Phase 1 ‚Üí Phase 5)  
**Estimated Time**: 8-12 hours for full implementation

---

## üéì Key Takeaways

### What Makes This EDA "Deep"?
1. ‚úÖ **16 questions** vs 4 basic charts (4√ó more comprehensive)
2. ‚úÖ **4 nh√≥m** organized by theme (not random charts)
3. ‚úÖ **Cross-analysis**: Category √ó City, Skills √ó Category, etc.
4. ‚úÖ **Advanced metrics**: Co-occurrence, concentration index, diversity score
5. ‚úÖ **Actionable insights**: Skills to learn, cities to target, companies to apply

### How This Differs from Basic EDA?
| Aspect | Basic EDA | Deep EDA (This Plan) |
|--------|-----------|----------------------|
| Questions | 3-4 | 16 |
| Charts | Bar, Pie | Bar, Heatmap, Facet, Box, Scatter |
| Insights | Descriptive | Descriptive + Cross-analysis + Recommendations |
| Skills | No | 4 dedicated questions (B1-B4) |
| Geo-analysis | No | Full nh√≥m (D1-D4) |
| Company | Maybe | 3 questions (C1, C3, C4) |
| Depth | Surface | Multi-dimensional |

### Answering Potential Questions

**Q1**: "T·∫°i sao c·∫ßn 16 questions? 4 bi·ªÉu ƒë·ªì kh√¥ng ƒë·ªß sao?"  
**A**: 4 bi·ªÉu ƒë·ªì ch·ªâ m√¥ t·∫£ distribution c∆° b·∫£n. 16 questions tr·∫£ l·ªùi "WHY" v√† "SO WHAT":
- Nh√≥m B: Skills analysis ‚Üí Job seekers bi·∫øt h·ªçc skill g√¨
- Nh√≥m C: Company analysis ‚Üí Bi·∫øt c√¥ng ty n√†o hiring active
- Nh√≥m D: Geo-category ‚Üí Bi·∫øt city n√†o ph√π h·ª£p v·ªõi skills m√¨nh

**Q2**: "C√≥ c·∫ßn heatmap, co-occurrence kh√¥ng? Ph·ª©c t·∫°p qu√°?"  
**A**: C·∫ßn! ƒê√¢y l√† ƒëi·ªÉm kh√°c bi·ªát gi·ªØa "EDA report" vs "data summary":
- Heatmap (D1): M·ªôt c√°i nh√¨n to√†n c·∫£nh city-category patterns
- Co-occurrence (B3): Skills recommendation ("H·ªçc React ‚Üí n√™n h·ªçc TypeScript")
- Kh√¥ng c√≥ ‚Üí ch·ªâ bi·∫øt "React ph·ªï bi·∫øn" (shallow insight)

**Q3**: "C√≥ th·ªÉ skip phase n√†o kh√¥ng?"  
**A**: 
- Phase 1 (Nh√≥m A): **KH√îNG TH·ªÇ SKIP** - fundamental distributions
- Phase 2 (Nh√≥m B): **N√äN L√ÄM** - skills l√† key value c·ªßa dataset
- Phase 3 (Nh√≥m C): Optional n·∫øu kh√¥ng quan t√¢m companies
- Phase 4 (Nh√≥m D): **N√äN L√ÄM** - geo insights r·∫•t quan tr·ªçng
- Phase 5: Optional nh∆∞ng n√™n c√≥ summary

**Recommended minimum**: Phase 1 + Phase 2 + Phase 4 (10/16 questions)

---

**Ready to implement!** üöÄ
